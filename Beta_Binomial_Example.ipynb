{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a very simple example of Bayesian parameter estimation using the Beta-Binomial model. Both analytical and simulation-based results are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approaches to Data Analysis\n",
    "\n",
    "><i>\"All models are wrong, but some are useful\"</i> -- George Box\n",
    "\n",
    "When performing statistical analyses, probabilistic assumptions are often made. Broadly speaking, there are three commonly used levels of assumptions (listed below).  At each level, the assumptions made increase, as does the possibility that the added assumptions are wrong, but hopefully they are useful.\n",
    "\n",
    "### 1. Exploratory\n",
    "><p>Descriptive statistics without any probabilistic assumptions\n",
    "><p>Examples include: Average, Median, Quantiles, Range, Variance, Minimum/Maximum, Histogram, and various other plots and charts\n",
    "\n",
    "<i>[Note: Quantities in items 2 & 3, below, can be scalars or vectors.]</i>\n",
    "\n",
    "### 2. Frequentist\n",
    "><p>The basic frequentist probability model consists of a random variable or vector (RV), $X$, with a cumulative distribution function, $F$, and fixed, deterministic parameters, $\\theta_1, ..., \\theta_m$.</p>\n",
    "><p>$$X \\sim F(x;\\theta_1, ..., \\theta_m)$$</p>\n",
    "><p>For example, the standard normal model is $F(x; \\mu, \\sigma) = \\Phi(\\frac{x-\\mu}{\\sigma})$,</p>\n",
    "><p>where $\\frac{d}{dz}\\Phi(z) = \\phi(z) = \\frac{1}{\\sqrt {2\\pi}} e^{-z^2/2}$\n",
    "\n",
    "### 3. Bayesian\n",
    "><p>The basic Bayesian probability model is similar to the Frequentist model except that it goes a step further and assumes that the parameters, themselves, are RVs with their own cumulative distribution functions and parameters (e.g., $G$ and $\\gamma$, resp. below).</p>\n",
    "><p>For example,</p>\n",
    "><p>$(X \\mid \\Theta=\\theta) \\sim F(x;\\theta)$, called the <b>Likelihood Distribution</b></p>\n",
    "><p>$\\Theta \\sim G(\\theta;\\gamma)$, called the <b>Prior Distribution</b></p>\n",
    "><p>$\\gamma$ is called a <b>hyperparameter</b> and is usually deterministic</p>\n",
    "><p>The next section provides an example.\n",
    "\n",
    "To make inferences about a Frequentist or Bayesian probability model of $X$ it is necessary to estimate the parameters of the model, $F$.\n",
    "\n",
    "In the Frequentist case, the Maximum Likelihood Estimate (MLE) is typically derived. The MLE is a deterministic value.\n",
    "\n",
    "In the Bayesian case, we assume we know the prior distributions of the parameters of $F$, so we seek to understand how observed values of $X$ affect that prior knowledge.  To do this, we need to obtain the conditional probability distribution of the parameters, given the observed data:\n",
    "><p>$P(\\Theta \\mid X=x)$, called the <b>Posterior Distribution</b></p>\n",
    "\n",
    "Depending on the type of likelihood and prior, the analytical derivation of the posterior might be intractable, so simulation is used to approximate it.  A simple example of such a simulation follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta-Binomial Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple and often-sited example of Bayesian parameter estimation. The posterior distribution can be analytically derived. Also, the prior and posterior are from the same family of distributions, [Beta](https://en.wikipedia.org/wiki/Beta_distribution), and so the prior distribution is called a <b>Conjugate Distribution for the likelihood</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we've conducted an experiment consisting of $n$ [binomial trials](https://en.wikipedia.org/wiki/Binomial_distribution) with an unknown probability of success, $\\theta$, and that we've observed $k_{obs}$ successes.\n",
    "\n",
    "We'll use the following values for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20  # Number of trials\n",
    "k_obs = 6  # Number of observed successes in n trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Frequentist Binomial Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the parameter, $\\theta$, is an unknown deterministic value.\n",
    "<p>$$K \\sim Binomial_n(k;\\theta) \\equiv \\binom{n}{k} \\theta^k(1-\\theta)^{n-k}$$</p>\n",
    "<p>where $n \\in \\mathbb{N}$, $k \\in \\{0, ... ,n\\}$, and $\\theta \\in [0,1]$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
