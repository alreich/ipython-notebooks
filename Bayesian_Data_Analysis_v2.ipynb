{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Brief Introduction to Bayesian Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Version 2</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How one conducts and interprets statistical inferences has been the subject of much debate for many decades.  In the 20th century, the debate was mostly over the <b>Frequentist</b> vs. the <b>Fisherian</b> approaches.  The <b>Bayesian</b> approach was also around during that time, but did not become practical until the 1990s with the advent of efficient simulation methods, such as <b>Markov Chain Monte Carlo (MCMC)</b>, and widespread access to powerful computers. Here, I'll refer the Frequentist and Fisherian approaches as the <b>Classical</b> approach. Today, the debate over how to conduct and interpret statistical inference is more about the Classical vs. Bayesian approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to provide a brief look at <b>Bayesian Data Analysis (BDA)</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, statistical analyses can be viewed in terms of the mathematical assumptions they make. Three broad categories are listed below, where each one makes successively greater assumptions than the previous one:\n",
    "1. <b>Exploratory Data Analysis</b> -- No probability model; just descriptive statistics\n",
    "1. <b>Classical Data Analysis</b> -- Probability model with fixed parameter\n",
    "1. <b>Bayesian Data Analysis</b> -- Probability model with random parameter, with its own model & fixed <i>hyper-parameter</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three subsections go into a bit more depth on each of these three categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No probability model.\n",
    "\n",
    "#### Examples\n",
    "\n",
    "* Average\n",
    "* Median\n",
    "* Quantiles\n",
    "* Range\n",
    "* Minimum/Maximum\n",
    "* Histogram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Classical Data Analysis\n",
    "\n",
    "The probability model consists of a random variable, $X$, with a probability distribution, $F$ and a fixed parameter $\\theta$:\n",
    "\n",
    "$X \\sim F(x;\\theta)$\n",
    "\n",
    "#### Example #1\n",
    "\n",
    "<i><u>Continuous Case</u></i>\n",
    "\n",
    "$\\Phi(x) = \\frac{1}{{\\sqrt {2\\pi}}}e^{-x^2/2}$ is the <b>standard normal distribution</b> function.\n",
    "\n",
    "Let $\\theta = \\begin{pmatrix} \\mu \\\\ \\sigma \\end{pmatrix}$, where $- \\infty < \\mu < + \\infty$ and $\\sigma > 0$,\n",
    "\n",
    "$x$ represents the outcome, where $- \\infty < x < + \\infty$,\n",
    "\n",
    "then $F(x;\\theta) \\equiv \\Phi({{x - \\mu} \\over \\sigma})$ is one of the most commonly used probabilistic models in all of statistics.\n",
    "\n",
    "#### Example #2\n",
    "\n",
    "<i><u>Discrete Case</u></i>\n",
    "\n",
    "The <b>binomial probability distribution</b>, $Binom(n,k,\\theta)$, is a discrete distribution representing the probability of $k$ successes in $n$ independent trials, where the probability of success on each individual trial is $\\theta$, where $0 \\le \\theta \\le 1$.\n",
    "\n",
    "$K$ is used here for the name of the random variable instead of $X$\n",
    "\n",
    "and $k$, rather than $x$, represents the outcome,\n",
    "\n",
    "then $K \\sim Binom(n,k,\\theta) \\equiv \\binom{n}{k} \\theta^k(1-\\theta)^{n-k}$\n",
    "> <p>where</p>\n",
    "> <p>$n \\in \\{1,2,3,...\\}$ -- The fixed number of trials</p>\n",
    "> <p>$k \\in \\{0,1,2,...,n\\}$ -- Number of successes in n trials (the outcome)</p>\n",
    "> <p>$\\theta \\in [0,1]$ -- The fixed probability of success for each trial</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bayesian Data Analysis\n",
    "\n",
    "<i>(NOTE: This starts out like the Classical approach, except that it goes a step further by assuming that the parameter itself has a model.)</i>\n",
    "\n",
    "Assumes a random variable, $X$, with a specific probability distribution, $F$, and <b>random</b> parameter, $\\Theta$, with its own distribution, $G$, and fixed parameter, $\\gamma$, sometimes called a hyper-parameter:\n",
    "\n",
    "$X \\sim F(x;\\Theta)$ where $\\Theta \\sim G(\\theta;\\gamma)$\n",
    "\n",
    "$G$ is called a <b><i>prior</i></b> distribution.\n",
    "\n",
    "#### Example #3\n",
    "\n",
    "<i><u>Discrete Case</u></i>\n",
    "\n",
    "Building on the discrete model in Example #2, above, except that instead of a fixed success probability, $\\theta$, here it is assumed to be a random variable, $\\Theta$, with its own distribution (and parameters), in this example, a <b>Beta distribution</b>, $Beta(\\alpha, \\beta)$.\n",
    "\n",
    "$K \\sim Binomial(n,k,\\Theta) \\equiv \\binom{n}{k} \\Theta^k(1-\\Theta)^{n-k}$\n",
    "> <p>where</p>\n",
    "> <p>$n \\in \\{1,2,3,...\\}$ -- Number of trials (a fixed value)</p>\n",
    "> <p>$k \\in \\{0,1,2,...,n\\}$ -- Number of successes</p>\n",
    "> <p>$\\Theta \\in [0,1] \\sim Beta(\\alpha, \\beta) \\equiv \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)} \\theta^{\\alpha - 1} (1-\\theta)^{\\beta - 1}$, where $\\alpha > 0$ and $\\beta > 0$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatch Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Probability Theory</i></b> is a subfield of Mathematics that is concerned with mathematical models of random phenomena.\n",
    "\n",
    "\n",
    "<i><b>Mathematical Statistics</b></i> is a subfield of Probability Theory concerned with the derivation of features of a probability model based on a set of <b>Random Variables (RV)</b> from the model.\n",
    "\n",
    "<i><b>Applied Statistics</b></i> utilizes the results of Mathematical Statistics by replacing the set of RVs with actual observed data to make <b>statistical inferences</b>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
